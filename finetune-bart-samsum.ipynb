{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:03:18.353410Z",
     "iopub.status.busy": "2023-08-02T18:03:18.353035Z",
     "iopub.status.idle": "2023-08-02T18:04:00.435907Z",
     "shell.execute_reply": "2023-08-02T18:04:00.434693Z",
     "shell.execute_reply.started": "2023-08-02T18:03:18.353379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Collecting rouge.score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.16.0)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.6.7)\n",
      "Collecting pycryptodomex>=3.6.6 (from py7zr)\n",
      "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr)\n",
      "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr)\n",
      "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr)\n",
      "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting brotli>=1.0.9 (from py7zr)\n",
      "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr)\n",
      "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n",
      "Building wheels for collected packages: rouge.score\n",
      "  Building wheel for rouge.score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge.score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=b6fabf350d8fec63f2bd7822135b9dd5b3a1159970edf6dc56e3e48b3235679d\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge.score\n",
      "Installing collected packages: brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, rouge.score, py7zr\n",
      "Successfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 rouge.score-0.1.2\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.20.3\n",
      "    Uninstalling accelerate-0.20.3:\n",
      "      Successfully uninstalled accelerate-0.20.3\n",
      "Successfully installed accelerate-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets \n",
    "!pip install rouge.score nltk py7zr\n",
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:04:00.438791Z",
     "iopub.status.busy": "2023-08-02T18:04:00.438315Z",
     "iopub.status.idle": "2023-08-02T18:04:03.760172Z",
     "shell.execute_reply": "2023-08-02T18:04:03.759134Z",
     "shell.execute_reply.started": "2023-08-02T18:04:00.438753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_metric, load_from_disk ,DatasetDict\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:04:03.761982Z",
     "iopub.status.busy": "2023-08-02T18:04:03.761362Z",
     "iopub.status.idle": "2023-08-02T18:04:11.023056Z",
     "shell.execute_reply": "2023-08-02T18:04:11.022109Z",
     "shell.execute_reply.started": "2023-08-02T18:04:03.761953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e732b22f3f6f468bb394327ce5795889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732edfd00ed84b05abdde0b3979dac7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/770 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset samsum/samsum (download: 2.81 MiB, generated: 10.04 MiB, post-processed: Unknown size, total: 12.85 MiB) to /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b330000cf62469e8ffebaacdcdd7e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset samsum downloaded and prepared to /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2920e2ce82d44502a447c18f5e5ec883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('samsum',split=[\"train[:5000]\",\"validation[:625]\",\"test[:625]\"])\n",
    "data = DatasetDict({'train':data[0],'validation':data[1],'test':data[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:04:11.026865Z",
     "iopub.status.busy": "2023-08-02T18:04:11.025861Z",
     "iopub.status.idle": "2023-08-02T18:04:11.767530Z",
     "shell.execute_reply": "2023-08-02T18:04:11.766665Z",
     "shell.execute_reply.started": "2023-08-02T18:04:11.026801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581c27e7656c44edbe3aef25a15dfa3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric('rouge')\n",
    "model_checkpoints = 'facebook/bart-large-cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:04:11.770899Z",
     "iopub.status.busy": "2023-08-02T18:04:11.770604Z",
     "iopub.status.idle": "2023-08-02T18:04:18.303555Z",
     "shell.execute_reply": "2023-08-02T18:04:18.302645Z",
     "shell.execute_reply.started": "2023-08-02T18:04:11.770873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae1ab447f654be59d18f4084a3783de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbd7e1fb1594948a4ce1a2a3426d686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddf6cf997ce4187872ccab72757ab4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acb21615baa4d89afc83c1909cadc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a58d7397a14543b97bc88d4ccc1693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cd274a560d4326a6c5813c6f63d8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0df87d37a440b4a8047af7ae954909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6852c83c5ae2409dba244ad600e70d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_input = 512\n",
    "max_target = 128\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoints, use_fast=False)\n",
    "     \n",
    "\n",
    "def preprocess_data(data_to_process):\n",
    "  #get the dialogue text\n",
    "  inputs = [dialogue for dialogue in data_to_process['dialogue']]\n",
    "  #tokenize text\n",
    "  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "\n",
    "  #tokenize labels\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(data_to_process['summary'], max_length=max_target, padding='max_length', truncation=True)\n",
    "    \n",
    "  model_inputs['labels'] = targets['input_ids']\n",
    "  #reuturns input_ids, attention_masks, labels\n",
    "  return model_inputs\n",
    "     \n",
    "\n",
    "tokenize_data = data.map(preprocess_data, batched = True, remove_columns=['id', 'dialogue', 'summary'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:04:18.305573Z",
     "iopub.status.busy": "2023-08-02T18:04:18.305010Z",
     "iopub.status.idle": "2023-08-02T18:04:18.311613Z",
     "shell.execute_reply": "2023-08-02T18:04:18.310118Z",
     "shell.execute_reply.started": "2023-08-02T18:04:18.305535Z"
    }
   },
   "outputs": [],
   "source": [
    "#sample the data\n",
    "train_sample = tokenize_data['train']\n",
    "validation_sample = tokenize_data['validation']\n",
    "test_sample = tokenize_data['test']\n",
    "tokenize_data['train'] = train_sample\n",
    "tokenize_data['validation'] = validation_sample\n",
    "tokenize_data['test'] = test_sample\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:04:26.792625Z",
     "iopub.status.busy": "2023-08-02T18:04:26.792246Z",
     "iopub.status.idle": "2023-08-02T18:04:50.063084Z",
     "shell.execute_reply": "2023-08-02T18:04:50.062185Z",
     "shell.execute_reply.started": "2023-08-02T18:04:26.792592Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83860aee05642ff980ace73b1350a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0117a58ea4224055a1ff5600bf7522b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/309 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load model\n",
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)\n",
    "     \n",
    "\n",
    "#collator to create batches. It preprocess data with the given tokenizer\n",
    "collator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "     \n",
    "\n",
    "#####################\n",
    "# metrics\n",
    "# compute rouge for evaluation \n",
    "#####################\n",
    "\n",
    "def compute_rouge(pred):\n",
    "  predictions, labels = pred\n",
    "  #decode the predictions\n",
    "  decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  #decode labels\n",
    "  decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "  #compute results\n",
    "  res = metric.compute(predictions=decode_predictions, references=decode_labels, use_stemmer=True)\n",
    "  #get %\n",
    "  res = {key: value.mid.fmeasure * 100 for key, value in res.items()}\n",
    "\n",
    "  pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "  res['gen_len'] = np.mean(pred_lens)\n",
    "\n",
    "  return {k: round(v, 4) for k, v in res.items()}\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:05:05.629226Z",
     "iopub.status.busy": "2023-08-02T18:05:05.628514Z",
     "iopub.status.idle": "2023-08-02T18:05:10.333101Z",
     "shell.execute_reply": "2023-08-02T18:05:10.332022Z",
     "shell.execute_reply.started": "2023-08-02T18:05:05.629189Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "args = transformers.Seq2SeqTrainingArguments(\n",
    "    'output_bartSamsum',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size= 6,\n",
    "    gradient_accumulation_steps=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    eval_accumulation_steps=1,\n",
    "    fp16=True\n",
    "    )\n",
    "#only CUDA available -> fp16=True\n",
    "trainer = transformers.Seq2SeqTrainer(\n",
    "    model, \n",
    "    args,\n",
    "    train_dataset=tokenize_data['train'],\n",
    "    eval_dataset=tokenize_data['validation'],\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_rouge\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T18:05:21.228547Z",
     "iopub.status.busy": "2023-08-02T18:05:21.228171Z",
     "iopub.status.idle": "2023-08-02T20:40:20.858358Z",
     "shell.execute_reply": "2023-08-02T20:40:20.857323Z",
     "shell.execute_reply.started": "2023-08-02T18:05:21.228515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230802_180530-1rnoiuvd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/soumikdey810/huggingface/runs/1rnoiuvd' target=\"_blank\">spring-pyramid-41</a></strong> to <a href='https://wandb.ai/soumikdey810/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/soumikdey810/huggingface' target=\"_blank\">https://wandb.ai/soumikdey810/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/soumikdey810/huggingface/runs/1rnoiuvd' target=\"_blank\">https://wandb.ai/soumikdey810/huggingface/runs/1rnoiuvd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 2:34:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304804</td>\n",
       "      <td>52.235600</td>\n",
       "      <td>27.208600</td>\n",
       "      <td>43.092800</td>\n",
       "      <td>43.139100</td>\n",
       "      <td>25.427200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485100</td>\n",
       "      <td>0.319521</td>\n",
       "      <td>52.893800</td>\n",
       "      <td>27.692600</td>\n",
       "      <td>43.595600</td>\n",
       "      <td>43.613200</td>\n",
       "      <td>28.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.485100</td>\n",
       "      <td>0.324688</td>\n",
       "      <td>53.420500</td>\n",
       "      <td>27.637100</td>\n",
       "      <td>43.264800</td>\n",
       "      <td>43.300500</td>\n",
       "      <td>30.123200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.347889</td>\n",
       "      <td>53.029500</td>\n",
       "      <td>27.558400</td>\n",
       "      <td>42.977800</td>\n",
       "      <td>43.009700</td>\n",
       "      <td>30.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.384366</td>\n",
       "      <td>52.217900</td>\n",
       "      <td>26.525700</td>\n",
       "      <td>42.589200</td>\n",
       "      <td>42.588700</td>\n",
       "      <td>29.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.431833</td>\n",
       "      <td>51.723600</td>\n",
       "      <td>26.008300</td>\n",
       "      <td>41.942700</td>\n",
       "      <td>41.974200</td>\n",
       "      <td>32.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.454412</td>\n",
       "      <td>51.975800</td>\n",
       "      <td>26.090200</td>\n",
       "      <td>41.868000</td>\n",
       "      <td>41.897900</td>\n",
       "      <td>30.179200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.489519</td>\n",
       "      <td>51.880400</td>\n",
       "      <td>25.779600</td>\n",
       "      <td>41.860600</td>\n",
       "      <td>41.881700</td>\n",
       "      <td>31.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.512479</td>\n",
       "      <td>51.506800</td>\n",
       "      <td>25.563300</td>\n",
       "      <td>41.352000</td>\n",
       "      <td>41.346700</td>\n",
       "      <td>31.868800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.514933</td>\n",
       "      <td>51.650100</td>\n",
       "      <td>26.032400</td>\n",
       "      <td>41.922200</td>\n",
       "      <td>41.927000</td>\n",
       "      <td>31.673600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2780, training_loss=0.17351095213306894, metrics={'train_runtime': 9299.2743, 'train_samples_per_second': 5.377, 'train_steps_per_second': 0.299, 'total_flos': 5.41776150528e+16, 'train_loss': 0.17351095213306894, 'epoch': 10.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T20:49:52.082609Z",
     "iopub.status.busy": "2023-08-02T20:49:52.082238Z",
     "iopub.status.idle": "2023-08-02T20:53:25.548430Z",
     "shell.execute_reply": "2023-08-02T20:53:25.547403Z",
     "shell.execute_reply.started": "2023-08-02T20:49:52.082576Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_results = trainer.predict(\n",
    "            tokenize_data['test'], metric_key_prefix=\"predict\", num_beams=5\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T20:55:08.041431Z",
     "iopub.status.busy": "2023-08-02T20:55:08.041032Z",
     "iopub.status.idle": "2023-08-02T20:55:08.054828Z",
     "shell.execute_reply": "2023-08-02T20:55:08.053811Z",
     "shell.execute_reply.started": "2023-08-02T20:55:08.041397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict_loss': 0.5358952879905701,\n",
       " 'predict_rouge1': 50.4775,\n",
       " 'predict_rouge2': 24.375,\n",
       " 'predict_rougeL': 40.2427,\n",
       " 'predict_rougeLsum': 40.2307,\n",
       " 'predict_gen_len': 30.8224,\n",
       " 'predict_runtime': 213.4521,\n",
       " 'predict_samples_per_second': 2.928,\n",
       " 'predict_steps_per_second': 0.492}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T20:55:14.841798Z",
     "iopub.status.busy": "2023-08-02T20:55:14.841417Z",
     "iopub.status.idle": "2023-08-02T20:55:15.002580Z",
     "shell.execute_reply": "2023-08-02T20:55:15.001573Z",
     "shell.execute_reply.started": "2023-08-02T20:55:14.841765Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = tokenizer.batch_decode(\n",
    "                    predict_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "                )\n",
    "import numpy as np\n",
    "labels = np.where(predict_results.label_ids != -100, predict_results.label_ids, tokenizer.pad_token_id)\n",
    "actual = tokenizer.batch_decode(\n",
    "                    labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "                )\n",
    "from nltk.tokenize import sent_tokenize\n",
    "preds = [pred.strip() for pred in predictions]\n",
    "labels = [label.strip() for label in actual]\n",
    "\n",
    "# rougeLSum expects newline after each sentence\n",
    "preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds] #predicted summary\n",
    "labels = [\"\\n\".join(sent_tokenize(label)) for label in labels] #actual summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T20:55:18.101095Z",
     "iopub.status.busy": "2023-08-02T20:55:18.100437Z",
     "iopub.status.idle": "2023-08-02T20:55:18.153191Z",
     "shell.execute_reply": "2023-08-02T20:55:18.149641Z",
     "shell.execute_reply.started": "2023-08-02T20:55:18.101052Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Dialogue\":data[\"test\"][\"dialogue\"],\"Actual Summary\":labels,'Model Summary':preds})\n",
    "df.to_csv('outputBartSamsum.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
