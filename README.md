# ME_THESIS_WORK_SD
Abstractive text summarization entails producing summaries that encompass the essential
concepts present in the original text. Unlike extractive summarization, abstractive summarization
can include new expressions and sentences absent from the original text. This thesis
presents a comprehensive analysis of abstractive summarization using the salience allocation
technique. The study incorporates a novel summarization model called SEASON. SEASON
uses the distribution of anticipating relevance to facilitate abstractive text summarization,
effectively responding to the content with various levels of abstraction.

This thesis work aims to assess SEASON’s performance in guiding effective abstractive
summarization across diverse articles and conversations, comparing it with the latest models
like BART, PEGASUS, and ProphetNet fine-tuned for text summarization tasks. The focus
is on measuring the quality and effectiveness of the generated summaries, considering their
ability to capture essential information and produce concise and coherent summaries.

The CNN/Dailymail and SAMSum datasets are used to conduct this study. In the study,
the performance of these models in text summarization is assessed using a range of evaluation
metrics. These metrics include ROUGE, METEOR, MoverScore, and BERTScore.
Analyzing the evaluation results enables a comprehensive comparison of the strengths and
weaknesses exhibited by each model.
This study sheds light on SEASON’s potential as a novel summarization model. It provides
awareness of the benefits and restrictions of different models in salience allocation. The
findings contribute to advancing the field of abstractive summarization and provide valuable
guidance for future research endeavors.
